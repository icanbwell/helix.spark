name: Build Java Base Image

# Controls when the action will run. Triggers the workflow on push or pull request
# events but only for the master branch
on:
  workflow_dispatch:
#  release:
#    types: [created
    
env:
  IMAGE_NAME: helix-spark-py
  REPOSITORY_URL: 400686897767.dkr.ecr.us-east-1.amazonaws.com


jobs:
  build_and_deploy_to_ecr:
    # The type of runner that the job will run on
    # uses https://github.com/apache/spark/blob/master/bin/docker-image-tool.sh
    # docker files are here: https://github.com/apache/spark/tree/master/resource-managers/kubernetes/docker/src/main/dockerfiles/spark
    # export ARCHS=--platform linux/arm/v7,linux/arm64/v8,linux/amd64

    #    runs-on: ubuntu-latest
    runs-on: [self-hosted, main]

    steps:
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0 # Required due to the way Git works, without it this action won't be able to find any or the correct tags
      - name: 'Get Previous tag'
        id: previoustag
        uses: WyriHaximus/github-action-get-previous-tag@v1
      - uses: actions/setup-python@v3
        with:
          python-version: '3.8'
      - uses: actions/setup-java@v3
        with:
          distribution: 'temurin' # See 'Supported distributions' for available options
          java-version: '17'
      - uses: vemonet/setup-spark@v1
        with:
          spark-version: '3.3.0' # Exact version
          hadoop-version: '3'
      - run: spark-submit --version
      - name: Set up QEMU
        uses: docker/setup-qemu-action@v2
        with:
          image: tonistiigi/binfmt:latest
          platforms: arm64
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v2
#      - name: Login to DockerHub
#        uses: docker/login-action@v2
#        with:
#          username: ${{ secrets.DOCKERHUB_USERNAME }}
#          password: ${{ secrets.DOCKERHUB_TOKEN }}
      
      - name: create buildx context
        run: |
          docker buildx create --use
      - name: list SPARK_HOME folder
        run: |
          ls -halt $SPARK_HOME
      - name: list SPARK_HOME Python folder
        run: |
          ls -halt $SPARK_HOME/kubernetes/dockerfiles/spark/bindings/python
# This publishes to two repos:
# 1. A Plain Java Spark image to https://hub.docker.com/repository/docker/bwell-helix/spark/tags?page=1&ordering=last_updated
# 2. A Java Spark image with Python to https://hub.docker.com/repository/docker/bwell-helix/spark-py/tags?page=1&ordering=last_updated
#      - name: build docker java 15 images
#        run: |
#          $SPARK_HOME/bin/docker-image-tool.sh -r bwell-helix -t java15-${{ steps.previoustag.outputs.tag }} -X -f $SPARK_HOME/kubernetes/dockerfiles/spark/Dockerfile -p $SPARK_HOME/kubernetes/dockerfiles/spark/bindings/python/Dockerfile -b java_image_tag=15-slim build
#          docker tag bwell-helix/spark-py:java15-${{ steps.previoustag.outputs.tag }} bwell-helix/spark-py:java15-latest
      - name: AWS Credentials
        uses: aws-actions/configure-aws-credentials@v1
        with:
          aws-region: us-east-1
          role-to-assume: arn:aws:iam::875300655693:role/prod-ue1-k8s-service-account-github-actions-runner
          role-session-name: JavaBaseImageBuild
          role-duration-seconds: 3600

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v1

      - name: build docker java 17 images
        run: |
          curl https://raw.githubusercontent.com/apache/spark/master/resource-managers/kubernetes/docker/src/main/dockerfiles/spark/Dockerfile --output $SPARK_HOME/kubernetes/dockerfiles/spark/Dockerfile
          ls -halt $SPARK_HOME/kubernetes/dockerfiles/spark
          $SPARK_HOME/bin/docker-image-tool.sh -r $REPOSITORY_URL -t java17-1.0.0 -X -f $SPARK_HOME/kubernetes/dockerfiles/spark/Dockerfile -p $SPARK_HOME/kubernetes/dockerfiles/spark/bindings/python/Dockerfile -b java_image_tag=17-jre-jammy build
          docker push $REPOSITORY_URL/$IMAGE_NAME:java17-1.0.0 $REPOSITORY_URL/$IMAGE_NAME:java17-latest
