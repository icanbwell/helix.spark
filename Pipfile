[[source]]
url = "https://pypi.python.org/simple"
verify_ssl = true
name = "pypi"

[packages]
wheel=">=0.37.1"
protobuf="==3.20.*"
"sparkdataframecomparer" = "==1.0.7"
sparkautomapper = "==1.0.19"
"sparkfhirschemas" = "==1.0.14"
sparkpipelineframework = "==1.0.55"
"sparkautomapper.fhir" = "==1.0.26"
py4j = "==0.10.9.5" # https://spark.apache.org/docs/latest/api/python/getting_started/install.html#dependencies
pyspark="==3.3.0"  # should match the version of spark we use for testing
delta-spark="==2.1.0"
requests = ">=2.28.1"
furl = ">=2.1.3"
structlog = ">=22.1.0"
boto3 = ">=1.26.5"
virtualenv = ">=20.16.6"
"helix.events.sdk" = "==0.1.0"
smart-open = {extras = ["s3"], version = ">=6.1.0"}
pymongo="==4.2.0"
pyathena = ">=2.14.0"
fastjsonschema= ">=2.16.1"
"helix.fhir.client.sdk" = "==1.0.28"
opensearch-py= "==1.1.0"
"helix.catalog-sdk" = "==0.2.9"
types-dataclasses=">=0.6.4"
types-requests=">=2.27.27"
types-PyMySQL=">=0.1.5"
typed-ast = ">=1.5.4"
types-urllib3 = ">=1.26.10"
lxml-stubs = ">=0.3.1"
types-jsonschema = ">=4.4.1"
types-boto3 = ">=1.0.2"
slack_sdk = ">=3.19.3"
bounded-pool-executor = ">=0.0.3"
better-exceptions = ">=0.3.3"
spark-nlp = ">=4.2.2"

[dev-packages]
pre-commit=">=2.20.0"
autoflake=">=1.7.7"
mypy = "==0.990"
pytest = "==7.2.0"
importlib-metadata = ">=4.0.1"
deepdiff = { version = ">=5.8.1", extras = ["murmur"] }
responses = ">=0.21.0"
pandas = "==1.2.5"
dictdiffer = ">=0.9.0"
# used to split the tests and run in parallel on GitHub Actions
pytest-split = ">=0.8.0"
black = ">=22.10.0"
moto = ">=4.0.9"
faker=">=14.1.0"
openpyxl=">=3.0.10"
Sphinx="==4.1.2"
sphinx-autoapi="==2.0.0"
sphinx-rtd-theme="==1.0.0"
myst-parser="==0.17.2"
rapidfuzz="==2.11.1"
"sparkpipelineframework.testing" = "==1.1.36"
helix-mockserver-client=">=1.0.0"
#rich = ">=12.0.0"
pytest-asyncio = ">=0.20.1"
python-dotenv = ">=0.21.0"

[requires]
python_version = "3.7"

[pipenv]
allow_prereleases = false
